<!DOCTYPE html>
<head><title>Hello Array - WebGPU</title></head>
<body>
  Use WebGPU to run a compute shader that uses f16 to multiply a number by 0.5 a bunch of times in a row.
  <p>
  <a href='https://github.com/toji/hello-triangle-webgpu/blob/main/hello-array.html'>See the Source</a>
  <p>
  See also <ul>
  <li> <a href="hello-array.html">Hello array</a><br/>
  <li> <a href="hello-f16.html">Hello f16</a><br/>
  </ul>
  <hr>
  <div id="target"></div>
  <script type='module'>
  function write(s) {
    document.getElementById("target").innerHTML += s + '<br/>';
  }
  // Check for WebGPU support first by seeing if navigator.gpu exists.
  if (!navigator.gpu) {
    write('<b>This browser does not support WebGPU.</b>');
    document.body.replaceChild(errorMessage, canvas);
  }

  // WebGPU apps start by getting an Adapter, which represents a physical GPU.
  const adapter = await navigator.gpu.requestAdapter({powerPreference: "high-performance"});

  // Check for shader-f16
  if (adapter.features.has('shader-f16')) {
    write("has shader-f16");
    console.log("has shader-f16!");
  } else {
    write("does not have shader-f16");
    console.log("does not have shader-f16!");
  }

  console.log([...adapter.features.values()]);
  const info = await adapter.requestAdapterInfo();
  console.log(info);

  const requiredFeatures = [];
  requiredFeatures.push('shader-f16');

  // From the adapter, you get a Device, which is the primary WebGPU interface.
  const device = await adapter.requestDevice({requiredFeatures});

  // We're going to make a big array, fill it with data, and get a compute shader
  // to double each entry in the array.
  const iters = 30;
  const bufSize = iters * 4;

  // Here's the buffer we'll put our initial data into.
  // We can only read or write a buffer when it's mapped into host (CPU) memory.
  const inputBuffer = device.createBuffer({
    size: 4,  // Number of bytes
    // MAP_WRITE: the CPU can write to the bufer when the buffer is mapped,
    // COPY_SRC: we'll be able to ask the GPU to copy from this buffer to another GPU resource.
    usage: GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC,
    mappedAtCreation: true,
  });
  // Get a view into the (already-mapped) buffer so we can read it like an array
  // of 32-bit floats.
  const input = new Float32Array(inputBuffer.getMappedRange());
  input[0] = 1.0;
  write(`input[0]: ${input[0]}`);

  // Unmap the input buffer from CPU's memory, so it can be used exclusively by the GPU.
  inputBuffer.unmap();

  // Create a buffer the compute shader will read and write.
  // It will only ever be visible on the GPU.
  const gpuBuffer = device.createBuffer({
    size: bufSize,
    // The compute shader will use it as a "storage" buffer, for reading
    // and writing. It will also be where we copy data into, and copy data out of.
    usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST | GPUBufferUsage.COPY_SRC,
  });
  // Create a buffer to copy the output to.
  const outputBuffer = device.createBuffer({
    size: bufSize,
    // The CPU will be able to copy into this bufer, and the CPU will be able to
    // map it for reading.
    usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST,
  });

  // Here's the compute shader.
  const shader = device.createShaderModule({code: `
    enable f16;
    @group(0) @binding(0) var<storage,read_write> buf: array<f32>;

    @compute @workgroup_size(1)
    fn f16divider() {
      var value: f16 = f16(buf[0]);
      for (var i: u32 = 0; i < arrayLength(&buf); i++) {
         buf[i] = f32(value);
         value *= 0.5h;
      }
    }
  `});
  // Create a pipeline from the shader. This puts the shader into context,
  // and can take some time because backend code generation often happens here.
  // There are async forms of this too.
  const pipeline = device.createComputePipeline({
    // "auto" layout says to the layouts of resources from the resource variables
    // used in the shader, i.e. with @group and @binding attributes.
    layout: "auto",
    compute: {
      module: shader, // The shader we created earlier.
      entryPoint: 'f16divider'
    }
  });
  // Specify the buffer resources that we'll attach to the pipeline later.
  const bindGroup = device.createBindGroup({
   layout: pipeline.getBindGroupLayout(0),
   // The group has just one resource, the gpuBuffer. Map to the whole buffer.
   entries: [{binding: 0, resource: {buffer: gpuBuffer}}],
  });

  // Now record the commands to actually do the work.
  const encoder = device.createCommandEncoder();
  // Copy the input buffer (which must be unmapped), to the GPU buffer.
  encoder.copyBufferToBuffer(inputBuffer, 0, gpuBuffer, 0, 4);
  // Now prepare to record GPU compute work.
  const computeEncoder = encoder.beginComputePass();
    computeEncoder.setPipeline(pipeline);  // Use the pipeline we created earlier
    computeEncoder.setBindGroup(0, bindGroup); // Attach the gpuBuffer to @group(0),@binding(0)
    computeEncoder.dispatchWorkgroups(1); // Launch the work.
    // That's all we'll do with this compute pipeline.
    // This will record the compute pipeline work into 'encoder'.
    computeEncoder.end();
  // After the compute shader completes, copy the gpuBuffer to outputBuffer
  encoder.copyBufferToBuffer(gpuBuffer, 0, outputBuffer, 0, bufSize);
  // And those are all the commands.
  const commands = encoder.finish({label: "f16divider"});

  // All the preparatory and potentially slow work has been done.
  // Now submit the recorded commands.  This is can go into an inner loop.
  // *Schedule* the work to be done. It likely starts right away, but this also
  // returns before the GPU is finished, so you can queue up more work if needed.
  device.queue.submit([commands]);
  // Schedule the task of mapping the output buffer back into CPU memory.
  outputBuffer.mapAsync(GPUMapMode.READ);
  // Wait for all queued work to finish, including the mapAsync (because the buffer was
  // exclusively in use by the scheduled work.)
  await device.queue.onSubmittedWorkDone();

  // Get a view into the output buffer, as an array of 32-bit floats.
  const mapped = outputBuffer.getMappedRange();
  const outFloat = new Float32Array(mapped);
  const outInt = new Uint32Array(mapped);

  // Show the outputs.
  write("Finished. Here are some outputs:");

  for (let i=0; i < iters; i++) {
    write(`[${i}]: 0x${outInt[i].toString(16)} ${outFloat[i]}`);
  }
  outputBuffer.unmap();

  device.destroy();
    </script>
  </body>
